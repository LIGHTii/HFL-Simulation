#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®åˆ’åˆ†éªŒè¯æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•å®¢æˆ·ç«¯æ•°æ®åˆ†é…çš„æ­£ç¡®æ€§å’Œä¸€è‡´æ€§
"""

import sys
import os
import torch
import numpy as np
from utils.options import args_parser
from utils.sampling import get_data
from utils.bipartite_bandwidth import run_bandwidth_allocation

def test_data_distribution_consistency():
    """æµ‹è¯•æ•°æ®åˆ†é…çš„ä¸€è‡´æ€§"""
    print("="*60)
    print("å®¢æˆ·ç«¯æ•°æ®åˆ†é…ä¸€è‡´æ€§æµ‹è¯•")
    print("="*60)
    
    # è§£æå‚æ•°
    args = args_parser()
    args.device = torch.device('cuda' if torch.cuda.is_available() and args.gpu != -1 else 'cpu')
    
    print(f"åˆå§‹å‚æ•°è®¾ç½®:")
    print(f"  æ•°æ®é›†: {args.dataset}")
    print(f"  è®¾å®šå®¢æˆ·ç«¯æ•°: {args.num_users}")
    print(f"  IIDæ¨¡å¼: {args.iid}")
    print(f"  Betaå‚æ•°: {getattr(args, 'beta', 'N/A')}")
    print(f"  ç½‘ç»œæ–‡ä»¶: {args.graphml_file}")
    
    # ç¬¬ä¸€æ­¥ï¼šè·å–ç½‘ç»œæ‹“æ‰‘ä¿¡æ¯
    print("\nç¬¬ä¸€æ­¥ï¼šåˆ†æç½‘ç»œæ‹“æ‰‘...")
    try:
        bipartite_graph, client_nodes, active_es_nodes, A_design, r_client_to_es, r_es, r_es_to_cloud, r_client_to_cloud = run_bandwidth_allocation(
            graphml_file=args.graphml_file, 
            es_ratio=args.es_ratio, 
            max_capacity=args.max_capacity, 
            visualize=False)
        
        if bipartite_graph is None:
            print("âŒ ç½‘ç»œæ‹“æ‰‘æ„å»ºå¤±è´¥")
            return False
        
        actual_num_users = len(client_nodes)
        print(f"âœ… ç½‘ç»œæ‹“æ‰‘åˆ†æå®Œæˆ")
        print(f"  å®é™…å®¢æˆ·ç«¯æ•°é‡: {actual_num_users}")
        print(f"  è¾¹ç¼˜æœåŠ¡å™¨æ•°é‡: {len(active_es_nodes)}")
        
        # æ›´æ–°å‚æ•°
        original_num_users = args.num_users
        args.num_users = actual_num_users
        print(f"  å‚æ•°æ›´æ–°: {original_num_users} -> {actual_num_users}")
        
    except Exception as e:
        print(f"âŒ ç½‘ç»œæ‹“æ‰‘åˆ†æå¤±è´¥: {e}")
        return False
    
    # ç¬¬äºŒæ­¥ï¼šè·å–æ•°æ®åˆ†é…
    print("\nç¬¬äºŒæ­¥ï¼šç”Ÿæˆå®¢æˆ·ç«¯æ•°æ®åˆ†é…...")
    try:
        dataset_train, dataset_test, dict_users, client_classes = get_data(args)
        print(f"âœ… æ•°æ®åˆ†é…ç”Ÿæˆå®Œæˆ")
        print(f"  è®­ç»ƒé›†å¤§å°: {len(dataset_train)}")
        print(f"  æµ‹è¯•é›†å¤§å°: {len(dataset_test)}")
        print(f"  åˆ†é…çš„å®¢æˆ·ç«¯æ•°: {len(dict_users)}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åˆ†é…ç”Ÿæˆå¤±è´¥: {e}")
        return False
    
    # ç¬¬ä¸‰æ­¥ï¼šè¯¦ç»†éªŒè¯æ•°æ®åˆ†é…
    print("\nç¬¬ä¸‰æ­¥ï¼šéªŒè¯æ•°æ®åˆ†é…ä¸€è‡´æ€§...")
    
    # æ£€æŸ¥1ï¼šå®¢æˆ·ç«¯æ•°é‡ä¸€è‡´æ€§
    if len(dict_users) != args.num_users:
        print(f"âŒ å®¢æˆ·ç«¯æ•°é‡ä¸ä¸€è‡´: dict_users={len(dict_users)}, args.num_users={args.num_users}")
        return False
    
    # æ£€æŸ¥2ï¼šå®¢æˆ·ç«¯IDè¿ç»­æ€§
    expected_ids = set(range(args.num_users))
    actual_ids = set(dict_users.keys())
    if expected_ids != actual_ids:
        print(f"âŒ å®¢æˆ·ç«¯IDä¸è¿ç»­")
        print(f"  æœŸæœ›: {sorted(expected_ids)}")
        print(f"  å®é™…: {sorted(actual_ids)}")
        return False
    
    # æ£€æŸ¥3ï¼šæ•°æ®ç´¢å¼•æœ‰æ•ˆæ€§
    total_samples = 0
    sample_counts = []
    invalid_clients = []
    
    for client_id, data_indices in dict_users.items():
        # å¤„ç†ä¸åŒçš„æ•°æ®ç»“æ„
        if isinstance(data_indices, set):
            indices_list = list(data_indices)
        elif isinstance(data_indices, np.ndarray):
            indices_list = data_indices.tolist()
        else:
            indices_list = list(data_indices)
        
        sample_counts.append(len(indices_list))
        total_samples += len(indices_list)
        
        # æ£€æŸ¥ç´¢å¼•èŒƒå›´
        if indices_list:
            min_idx = min(indices_list)
            max_idx = max(indices_list)
            
            if min_idx < 0 or max_idx >= len(dataset_train):
                invalid_clients.append({
                    'client_id': client_id,
                    'min_idx': min_idx,
                    'max_idx': max_idx,
                    'count': len(indices_list)
                })
    
    if invalid_clients:
        print(f"âŒ å‘ç°æ— æ•ˆæ•°æ®ç´¢å¼•:")
        for client in invalid_clients:
            print(f"  å®¢æˆ·ç«¯{client['client_id']}: ç´¢å¼•èŒƒå›´[{client['min_idx']}, {client['max_idx']}], æ•°æ®é›†å¤§å°{len(dataset_train)}")
        return False
    
    # æ£€æŸ¥4ï¼šæ•°æ®åˆ†é…ç»Ÿè®¡
    print(f"âœ… æ•°æ®åˆ†é…éªŒè¯é€šè¿‡:")
    print(f"  æ€»åˆ†é…æ ·æœ¬æ•°: {total_samples}")
    print(f"  æ•°æ®é›†æ€»å¤§å°: {len(dataset_train)}")
    print(f"  æ ·æœ¬åˆ©ç”¨ç‡: {total_samples/len(dataset_train)*100:.1f}%")
    print(f"  å¹³å‡æ¯å®¢æˆ·ç«¯: {np.mean(sample_counts):.1f}æ ·æœ¬")
    print(f"  æ ·æœ¬æ•°èŒƒå›´: [{min(sample_counts)}, {max(sample_counts)}]")
    print(f"  æ ·æœ¬æ•°æ ‡å‡†å·®: {np.std(sample_counts):.2f}")
    
    # æ£€æŸ¥5ï¼šå®¢æˆ·ç«¯ç±»åˆ«ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    if client_classes:
        print(f"  å®¢æˆ·ç«¯ç±»åˆ«ä¿¡æ¯: {len(client_classes)}ä¸ªå®¢æˆ·ç«¯æœ‰ç±»åˆ«ä¿¡æ¯")
        
        # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
        class_counts = {}
        for client_id, classes in client_classes.items():
            num_classes = len(classes) if isinstance(classes, (list, set, np.ndarray)) else 1
            class_counts[num_classes] = class_counts.get(num_classes, 0) + 1
        
        print(f"  ç±»åˆ«æ•°åˆ†å¸ƒ: {dict(sorted(class_counts.items()))}")
    
    print(f"\nğŸ‰ æ‰€æœ‰éªŒè¯éƒ½é€šè¿‡ï¼æ•°æ®åˆ†é…æ˜¯æ­£ç¡®å’Œä¸€è‡´çš„ã€‚")
    return True

def test_data_persistence():
    """æµ‹è¯•æ•°æ®æŒä¹…åŒ–åŠŸèƒ½"""
    print("\n" + "="*60)
    print("æ•°æ®æŒä¹…åŒ–åŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    # TODO: æ·»åŠ æ•°æ®ä¿å­˜å’ŒåŠ è½½çš„æµ‹è¯•
    print("æ•°æ®æŒä¹…åŒ–æµ‹è¯•å¾…å®ç°...")
    return True

if __name__ == "__main__":
    print("å¼€å§‹æ•°æ®åˆ†é…éªŒè¯æµ‹è¯•...\n")
    
    # æµ‹è¯•æ•°æ®åˆ†é…ä¸€è‡´æ€§
    success1 = test_data_distribution_consistency()
    
    # æµ‹è¯•æ•°æ®æŒä¹…åŒ–
    success2 = test_data_persistence()
    
    print("\n" + "="*60)
    if success1 and success2:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡ï¼")
        sys.exit(0)
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼")
        sys.exit(1)